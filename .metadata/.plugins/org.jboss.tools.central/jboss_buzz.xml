<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><entry><title>How to configure Helm charts using JKube, part 2</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/08/01/how-configure-helm-charts-using-jkube-part-2" /><author><name>Rohan Kumar</name></author><id>9fda19e5-56de-420b-b218-04b6ce9119fa</id><updated>2022-08-01T07:00:00Z</updated><published>2022-08-01T07:00:00Z</published><summary type="html">&lt;p&gt;&lt;a href="https://helm.sh/"&gt;Helm charts&lt;/a&gt; are a popular and convenient way to support different environments on &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt;. My previous article, &lt;a href="https://developers.redhat.com/articles/2022/04/14/generate-helm-charts-your-java-application-using-jkube-part-1"&gt;How Helm and JKube simplify Kubernetes management, part 1&lt;/a&gt;, explained why generating Helm charts for &lt;a href="https://developers.redhat.com/topics/enterprise-java"&gt;Java&lt;/a&gt; applications can be difficult and how it's made easier by &lt;a href="https://www.eclipse.org/jkube"&gt;Eclipse JKube&lt;/a&gt;, which has Maven and Gradle plugins.&lt;/p&gt; &lt;p&gt;In Part 1, you learned how to generate Helm charts for Java automatically without any configuration and to publish them to desired Helm registries. While a zero-configuration approach is a great way to get started, most projects tune the Eclipse JKube plugins to generate the Helm charts to meet their requirements.&lt;/p&gt; &lt;p&gt;This follow-up article explains how to configure Helm charts generated by JKube's Maven and Gradle plugins via various configuration options provided by Eclipse JKube.&lt;/p&gt; &lt;p&gt;Specifically, we will cover:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;XML&lt;/li&gt; &lt;li&gt;Java properties&lt;/li&gt; &lt;li&gt;Resource fragments&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Then we will conclude by demonstrating how to configure your Helm registry where you store your configuration.&lt;/p&gt; &lt;p&gt;Assuming you completed part one, you should already have the JKube Maven plugin (available in &lt;a href="https://github.com/rohankanojia-forks/eclipse-jkube-helm-demo"&gt;this Github repository&lt;/a&gt;) in your sample project:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-xml"&gt;&lt;dependency&gt; &lt;groupId&gt;org.eclipse.jkube&lt;/groupId&gt; &lt;artifactId&gt;openshift-maven-plugin&lt;/artifactId&gt; &lt;version&gt;${jkube.version}&lt;/version&gt; &lt;/dependency&gt;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;For this series of articles, we use the Maven plugin provided specifically for Red Hat Openshift. You can configure the Helm chart generated by JKube by overriding the opinionated default Helm configuration. The following sections describe how to customize charts via XML, Java properties, and resource fragments.&lt;/p&gt; &lt;h2&gt;Edit XML to configure Helm&lt;/h2&gt; &lt;p&gt;One way to configure a Helm chart managed by JKube is to directly edit the &lt;code&gt;pom.xml&lt;/code&gt; file in the JKube plugin configuration section. Override the default configuration by providing a &lt;code&gt;helm&lt;/code&gt; configuration option in the plugin's &lt;code&gt;configuration&lt;/code&gt; section. Here is an example:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-xml"&gt; &lt;plugin&gt; &lt;groupId&gt;org.eclipse.jkube&lt;/groupId&gt; &lt;artifactId&gt;openshift-maven-plugin&lt;/artifactId&gt; &lt;version&gt;${jkube.version}&lt;/version&gt; &lt;configuration&gt; &lt;helm&gt; &lt;chart&gt;${project.artifactId}&lt;/chart&gt; &lt;version&gt;${project.version}&lt;/version&gt; &lt;description&gt;JKube Helm Maven demo Helm Chart&lt;/description&gt; &lt;home&gt;https://www.eclipse.org/jkube/&lt;/home&gt; &lt;sources&gt; &lt;source&gt;https://github.com/eclipse/jkube&lt;/source&gt; &lt;/sources&gt; &lt;maintainers&gt; &lt;maintainer&gt; &lt;name&gt;Maintainer1&lt;/name&gt; &lt;email&gt;maintainer1@maintainer1.org&lt;/email&gt; &lt;url&gt;maintainer1.org&lt;/url&gt; &lt;/maintainer&gt; &lt;maintainer&gt; &lt;name&gt;Maintainer2&lt;/name&gt; &lt;email&gt;maintainer2@maintainer2.org&lt;/email&gt; &lt;url&gt;maintainer2.org&lt;/url&gt; &lt;/maintainer&gt; &lt;/maintainers&gt; &lt;icon&gt;https://helm.sh/img/helm.svg&lt;/icon&gt; &lt;keywords&gt;eclipse,jkube,kubernetes,maven&lt;/keywords&gt; &lt;sourceDir&gt;${project.basedir}/target/classes/META-INF/jkube&lt;/sourceDir&gt; &lt;outputDir&gt;${project.basedir}/target/jkube/helm&lt;/outputDir&gt; &lt;chartExtension&gt;tar.gz&lt;/chartExtension&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;name&gt;ingress-nginx&lt;/name&gt; &lt;version&gt;3.16.1&lt;/version&gt; &lt;repository&gt;https://kubernetes.github.io/ingress-nginx&lt;/repository&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/helm&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The complete set of supported configuration options is in the &lt;a href="https://www.eclipse.org/jkube/docs/openshift-maven-plugin#jkube:helm"&gt;oc:helm documentation&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Now run OpenShift Maven Plugin's resource and the Helm goal to regenerate the YAML manifests and Helm chart. I have added the plugin configuration in a separate xml-configuration profile.&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ ./mvnw oc:resource oc:helm -Pxml-configuration&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;After running that command, you should be able to see this generated Helm Chart:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;apiVersion: v1 name: jkube-helm-maven home: https://www.eclipse.org/jkube/ sources: - https://github.com/eclipse/jkube version: 1.0.0-SNAPSHOT description: JKube Helm Maven demo Helm Chart keywords: - eclipse - jkube - kubernetes - maven maintainers: - name: Maintainer1 email: maintainer1@maintainer1.org url: maintainer1.org - name: Maintainer2 email: maintainer2@maintainer2.org url: maintainer2.org icon: https://helm.sh/img/helm.svg dependencies: - name: ingress-nginx version: 3.16.1 repository: https://kubernetes.github.io/ingress-nginx &lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Configuring Helm using Java properties&lt;/h2&gt; &lt;p&gt;JKube also exposes the Helm configuration via Java properties. Here is an example of how to provide the configuration from the previous section using Maven properties:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-xml"&gt; &lt;profile&gt; &lt;id&gt;property-configuration&lt;/id&gt; &lt;properties&gt; &lt;jkube.helm.chart&gt;${project.artifactId}&lt;/jkube.helm.chart&gt; &lt;jkube.helm.version&gt;${project.version}&lt;/jkube.helm.version&gt; &lt;jkube.helm.description&gt;JKube Helm Maven demo Helm Chart (Properties)&lt;/jkube.helm.description&gt; &lt;jkube.helm.home&gt;https://www.eclipse.org/jkube/&lt;/jkube.helm.home&gt; &lt;jkube.helm.icon&gt;https://helm.sh/img/helm.svg&lt;/jkube.helm.icon&gt; &lt;jkube.helm.type&gt;openshift&lt;/jkube.helm.type&gt; &lt;jkube.helm.sourceDir&gt;${project.basedir}/target/classes/META-INF/jkube&lt;/jkube.helm.sourceDir&gt; &lt;jkube.helm.outputDir&gt;${project.basedir}/target/jkube/helm&lt;/jkube.helm.outputDir&gt; &lt;jkube.helm.chartExtension&gt;tar.gz&lt;/jkube.helm.chartExtension&gt; &lt;/properties&gt; &lt;/profile&gt;&lt;/code&gt;&lt;/pre&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;NOTE&lt;/strong&gt;: You can't configure complex elements such as maintainers and sources via properties.&lt;/p&gt; &lt;p&gt;Run the OpenShift Maven Plugin's resource and the Helm goal to regenerate the YAML manifests and Helm chart. As in the previous section, I have added the plugin configuration in a separate property-configuration profile.&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ ./mvnw oc:resource oc:helm -Pproperty-configuration&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;You should see the generated Helm chart in the &lt;code&gt;target/jkube/helm/openshift/&lt;/code&gt; directory. The chart's contents should be similar to the chart generated with the &lt;code&gt;xml-configuration&lt;/code&gt; profile in the previous step.&lt;/p&gt; &lt;h2&gt;Configuring Helm using resource fragments&lt;/h2&gt; &lt;p&gt;Suppose you want to apply a CustomResource object along with your regular Kubernetes resources during the "resource and apply" phase of the OpenShift Maven Plugin's run. It is impossible to provide a custom resource via an XML configuration or property. Instead, use the third method of generating a Helm chart: &lt;a href="https://www.eclipse.org/jkube/docs/openshift-maven-plugin#_resource_fragments"&gt;JKube resource fragments&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;JKube allows users to provide their Kubernetes YAML manifests in a specific directory. The manifests are automatically picked up during oc:resource goal and added to the Helm chart.&lt;/p&gt; &lt;p&gt;For this article, we will use the &lt;a href="https://kubernetes.io/docs/tasks/extend-kubernetes/custom-resources/custom-resource-definitions/#create-custom-objects"&gt;crontab CustomResource&lt;/a&gt; from the Kubernetes documentation. To start, apply the &lt;a href="https://kubernetes.io/docs/tasks/extend-kubernetes/custom-resources/custom-resource-definitions/#create-a-customresourcedefinition"&gt;crontab CustomResourceDefinition&lt;/a&gt; on OpenShift using the command-line tool:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ oc create -f crontab-crd.yml customresourcedefinition.apiextensions.k8s.io/crontabs.stable.example.com created &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Let's take a look at our crontab custom resource manifest. Usually, you would add this file to the &lt;code&gt;src/main/jkube&lt;/code&gt; directory (the default location of the resource directory). But in our case, we have configured a different resource directory (the &lt;code&gt;fragments&lt;/code&gt; folder in the root directory). The &lt;code&gt;fragments/jkube/crontab-cr.yaml&lt;/code&gt; file contains:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-python"&gt;apiVersion: "stable.example.com/v1" kind: CronTab metadata: name: ${project.artifactId} labels: helm.sh/chart: "${project.artifactId}-${crontab.release}" app.kubernetes.io/managed-by: "${crontab.managedby}" spec: cronSpec: ${crontab.spec} image: ${crontab.image} &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Note how we provide some of the values in this crontab resource fragment using fields enclosed in &lt;code&gt;${...}&lt;/code&gt;. You must define these values in the Helm parameter configurations, as in the following example:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-xml"&gt; &lt;plugin&gt; &lt;groupId&gt;org.eclipse.jkube&lt;/groupId&gt; &lt;artifactId&gt;kubernetes-maven-plugin&lt;/artifactId&gt; &lt;version&gt;${jkube.version}&lt;/version&gt; &lt;configuration&gt; &lt;resourceDir&gt;${project.basedir}/fragments/jkube&lt;/resourceDir&gt; &lt;helm&gt; &lt;parameters&gt; &lt;parameter&gt; &lt;name&gt;crontab.spec&lt;/name&gt; &lt;value&gt;{{ .spec | default "* * * * */5" | quote }}&lt;/value&gt; &lt;/parameter&gt; &lt;parameter&gt; &lt;name&gt;crontab.image&lt;/name&gt; &lt;value&gt;{{ .image | default "my-awesome-cron-image" | upper | quote }}&lt;/value&gt; &lt;/parameter&gt; &lt;parameter&gt; &lt;name&gt;crontab.release&lt;/name&gt; &lt;value&gt;{{ .Chart.Version }}&lt;/value&gt; &lt;/parameter&gt; &lt;parameter&gt; &lt;name&gt;crontab.managedby&lt;/name&gt; &lt;value&gt;jkube&lt;/value&gt; &lt;/parameter&gt; &lt;/parameters&gt; &lt;/helm&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;You can specify strings, Maven properties, or Helm template directives as values. Helm parameters can contain non-string fields and periods. JKube automatically resolves Maven properties in a &lt;code&gt;values.yaml&lt;/code&gt; file.&lt;/p&gt; &lt;p&gt;Run the OpenShift Maven Plugin's resource and the Helm goal to regenerate the YAML manifests and Helm chart. I have added the plugin configuration in a separate &lt;code&gt;fragment-configuration&lt;/code&gt; profile.&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ ./mvnw oc:resource oc:helm -Pfragment-configuration &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This results in the following crontab template:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ cat target/jkube/helm/jkube-helm-maven/openshift/templates/jkube-helm-maven-cr.yaml --- apiVersion: stable.example.com/v1 kind: CronTab metadata: labels: helm.sh/chart: "jkube-helm-maven-{{ .Chart.Version }}" app.kubernetes.io/managed-by: {{ .Values.crontab.managedby | default "jkube" }} app: jkube-helm-maven provider: jkube version: 1.0.0-SNAPSHOT group: org.eclipse.jkube.demos name: jkube-helm-maven spec: cronSpec: {{ .spec | default "* * * * */5" | quote }} image: {{ .image | default "my-awesome-cron-image" | upper | quote }} &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;JKube has replaced &lt;code&gt;${...}&lt;/code&gt; placeholders with values specified in the &lt;code&gt;parameter&lt;/code&gt; configurations. JKube also generated a &lt;code&gt;values.yaml&lt;/code&gt; file for later use by Helm for resolving values. You can inspect the generated &lt;code&gt;values.yaml&lt;/code&gt; file as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ cat target/jkube/helm/jkube-helm-maven/openshift/values.yaml --- crontab: managedby: jkube &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Next, install this Helm chart. You should see the crontab custom resource applied to the target cluster:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ helm install --generate-name target/jkube/helm/jkube-helm-maven/openshift/ NAME: openshift-1657293004 LAST DEPLOYED: Fri Jul 8 20:40:05 2022 NAMESPACE: default STATUS: deployed REVISION: 1 TEST SUITE: None &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Check the applied crontab resource:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ oc get crontab NAME AGE jkube-helm-maven 86s $ oc get crontab jkube-helm-maven -o yaml apiVersion: stable.example.com/v1 kind: CronTab metadata: annotations: meta.helm.sh/release-name: openshift-1657293004 meta.helm.sh/release-namespace: default labels: app: jkube-helm-maven app.kubernetes.io/managed-by: Helm group: org.eclipse.jkube.demos helm.sh/chart: jkube-helm-maven-1.0.0-SNAPSHOT provider: jkube version: 1.0.0-SNAPSHOT name: jkube-helm-maven namespace: default resourceVersion: "43872" uid: c7b8547e-d0c1-404f-842c-f8e265340b34 spec: cronSpec: '* * * * */5' image: MY-AWESOME-CRON-IMAGE &lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Configuring the Helm registry&lt;/h2&gt; &lt;p&gt;Apart from configuring Helm charts, you must configure the registry to which you will push your Helm chart. Like Helm charts, Helm registries can be configured via XML configuration or properties.&lt;/p&gt; &lt;p&gt;I used &lt;a href="https://chartmuseum.com/"&gt;ChartMuseum&lt;/a&gt; for my Helm registry. I have set up a local instance on my machine. You need to change the examples that follow to reflect your Helm registry.&lt;/p&gt; &lt;p&gt;If your project version is a snapshot, use the &lt;code&gt;snapshotRepository&lt;/code&gt; field for Helm registry configuration. Otherwise, use &lt;code&gt;stableRepository&lt;/code&gt;. We will use &lt;code&gt;snapshotRepository&lt;/code&gt; for this demo since it has a 1.0.0-SNAPSHOT Maven version:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-xml"&gt; &lt;plugin&gt; &lt;groupId&gt;org.eclipse.jkube&lt;/groupId&gt; &lt;artifactId&gt;kubernetes-maven-plugin&lt;/artifactId&gt; &lt;version&gt;${jkube.version}&lt;/version&gt; &lt;configuration&gt; &lt;helm&gt; &lt;snapshotRepository&gt; &lt;name&gt;ChartMuseum&lt;/name&gt; &lt;url&gt;http://localhost:8080/api/charts&lt;/url&gt; &lt;type&gt;CHARTMUSEUM&lt;/type&gt; &lt;username&gt;user1&lt;/username&gt; &lt;/snapshotRepository&gt; &lt;/helm&gt; &lt;/configuration&gt; &lt;/plugin&gt;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Once you have configured your Helm registry details, run the Helm push goal:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ ./mvnw oc:helm-push -Djkube.helm.snapshotRepository.password=secret&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This should upload the Helm chart to the specified registry. You can also provide all this configuration in the form of properties, as shown in the following command:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ ./mvnw oc:helm-push -Djkube.helm.snapshotRepository.name=ChartMuseum \ &gt; -Djkube.helm.snapshotRepository.url=http://localhost:8080/api/charts \ &gt; -Djkube.helm.snapshotRepository.type=CHARTMUSEUM \ &gt; -Djkube.helm.snapshotRepository.username=user1 \ &gt; -Djkube.helm.snapshotRepository.password=secret&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;It is also possible to provide registry credentials in Maven settings (&lt;code&gt;~/.m2/settings.xml&lt;/code&gt;) by specifying the Helm registry name and URL:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-xml"&gt; &lt;plugin&gt; &lt;groupId&gt;org.eclipse.jkube&lt;/groupId&gt; &lt;artifactId&gt;openshift-maven-plugin&lt;/artifactId&gt; &lt;version&gt;${jkube.version}&lt;/version&gt; &lt;configuration&gt; &lt;helm&gt; &lt;snapshotRepository&gt; &lt;name&gt;ChartMuseum&lt;/name&gt; &lt;url&gt;http://localhost:8080/api/charts&lt;/url&gt; &lt;type&gt;CHARTMUSEUM&lt;/type&gt; &lt;/snapshotRepository&gt; &lt;/helm&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;You can provide Helm registry credentials in the &lt;code&gt;server&lt;/code&gt; section of &lt;code&gt;settings.xml&lt;/code&gt;. The server ID must match the Helm registry name specified in the plugin configuration. JKube can automatically infer credentials from Maven settings:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-xml"&gt;&lt;?xml version="1.0" encoding="UTF-8"?&gt; &lt;settings xmlns="http://maven.apache.org/SETTINGS/1.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd"&gt; &lt;servers&gt; &lt;server&gt; &lt;id&gt;ChartMuseum&lt;/id&gt; &lt;username&gt;user1&lt;/username&gt; &lt;password&gt;secret&lt;/password&gt; &lt;/server&gt; &lt;/servers&gt; &lt;/settings&gt; &lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Customized JKube configurations&lt;/h2&gt; &lt;p&gt;So far, you have learned the different methods for generating and publishing Helm charts using Eclipse JKube plugins. We demonstrated how easy it is to customize various aspects of Helm charts and registries utilizing a rich set of configuration options. Please try one or more of these options and provide feedback regarding how we can improve your experience.&lt;/p&gt; &lt;p&gt;For more information, check out the &lt;a href="https://www.eclipse.org/jkube"&gt;Eclipse JKube website&lt;/a&gt;. Feel free to follow us on these channels:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://stackoverflow.com/questions/tagged/jkube"&gt;StackOverflow&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://www.youtube.com/channel/UCpU2tjgpfkTVgeDq-DBSV7A"&gt;YouTube Channel&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://twitter.com/jkubeio"&gt;Twitter&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://gitter.im/eclipse/jkube"&gt;Gitter Chat&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/08/01/how-configure-helm-charts-using-jkube-part-2" title="How to configure Helm charts using JKube, part 2"&gt;How to configure Helm charts using JKube, part 2&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Rohan Kumar</dc:creator><dc:date>2022-08-01T07:00:00Z</dc:date></entry><entry><title type="html">KIE Community welcomes IBM Business Automation</title><link rel="alternate" href="https://blog.kie.org/2022/07/ibm-rht.html" /><author><name>Mark Proctor</name></author><id>https://blog.kie.org/2022/07/ibm-rht.html</id><updated>2022-07-29T10:58:58Z</updated><content type="html">Alex Porcelli and I (Mark Proctor) are very pleased to announce IBM is joining Red Hat in the KIE community. This is a great opportunity to partner as we continue making innovative software for business automation and fostering a tradition of openness and inclusion in the open source arena.  We’re excited by the opportunities that lay ahead of us, and we wanted to reassure people that being true to Open Source roots remains integral to who we are and where we will go. As part of this transition, Alex and other members of the Red Hat team have joined the IBM Business Automation organization. From Alex: I’m thrilled and honored to join the IBM Business Automation organization, following my passion for the great PAM and DM open-source technologies. I’m also excited with the opportunity to continue collaborating with my friends and colleagues from Red Hat and the KIE community! WHAT THIS MEANS FOR THE COMMUNITY Two leaders in their respective places are joining together and bringing their expertise to the KIE community: IBM, with leadership in the business automation space, and Red Hat with leadership within open source. The KIE community will continue to expand and grow bringing in new contributors, expertise, and solutions. Red Hat and IBM plan to work together on the upstream projects, and we invite everyone else interested to join us to make these projects even better. We are also exploring moving the technologies to a Foundation as a means to make collaboration easier and allow for a wider network of collaborators. Community websites will be updated soon and the existing community channels (zulip and google groups) remain. WHAT THIS MEANS FOR END USERS AND CUSTOMERS Red Hat plans to work with IBM within the KIE community to provide Kogito as a shared foundational set of cloud-native technologies for event-driven architectures for rules, workflow and optimization – building on and comprising of Knative, Quarkus, jBPM, Drools and Optaplanner.  To align with Red Hat’s strategic direction for Kubernetes and OpenShift, as part of its work within Kogito, Red Hat will focus on Service Orchestration and Application Logic for OpenShift developers. A key aspect of this is Red Hat’s championing of CNCF’s Serverless Workflow specification.  IBM intends to introduce additional capabilities within the KIE community to appeal to the broader open-source Business Automation audience. They plan to continue investing in OMG specifications, specifically BPMN and DMN. In addition, they plan to combine the KIE cloud-native decisions and workflow with the OMG specs into their recently announced  standalone Open Source offerings.    Mark Proctor &amp;amp; Alex Porcelli The post appeared first on .</content><dc:creator>Mark Proctor</dc:creator></entry><entry><title>Red Hat Developer roundup: Best of July 2022</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/07/29/red-hat-developer-roundup-best-july-2022" /><author><name>Heiker Medina</name></author><id>34b403a3-f94b-4fe0-bca0-662f87d23cff</id><updated>2022-07-29T07:00:00Z</updated><published>2022-07-29T07:00:00Z</published><summary type="html">&lt;p&gt;Welcome to our monthly article recap, where we round up the latest popular content from Red Hat Developer in one helpful place. Like &lt;a href="https://developers.redhat.com/articles/2022/06/30/red-hat-developer-roundup-best-june-2022"&gt;last month&lt;/a&gt;, &lt;a href="https://developers.redhat.com/topics/gitops"&gt;GitOps&lt;/a&gt;, &lt;a href="https://developers.redhat.com/topics/go"&gt;Go&lt;/a&gt;, and &lt;a href="https://developers.redhat.com/topics/kubernetes/"&gt;Kubernetes&lt;/a&gt; &lt;a href="https://developers.redhat.com/topics/security/"&gt;security&lt;/a&gt; topics were in high demand from our readers. Without further ado, let's dive into the July highlights.&lt;/p&gt; &lt;h2&gt;GitOps workflows and security&lt;/h2&gt; &lt;p&gt;In GitOps, Git is not only your source of truth (as it is for most projects) but also your interface to your environment. Developers have used Git workflows for their application delivery method for years, and now operations teams must adopt similar workflows. GitOps advocate Christian Hernandez offered &lt;a href="https://developers.redhat.com/articles/2022/07/20/git-workflows-best-practices-gitops-deployments"&gt;tips and best practices to keep in mind for GitOps deployments&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Interested in diving deeper into GitOps principles? Download Christian's new e-book, &lt;a href="https://developers.redhat.com/e-books/path-gitops"&gt;&lt;em&gt;The Path to GitOps&lt;/em&gt;&lt;/a&gt;, to understand where GitOps fits in your &lt;a href="https://developers.redhat.com/topics/linux/"&gt;continuous integration/continuous delivery (CI/CD)&lt;/a&gt; pipelines. This short guide outlines the various tools and methods you can use to implement GitOps in your organization.&lt;/p&gt; &lt;p&gt;Sahil Sethi also showed you &lt;a href="https://developers.redhat.com/articles/2022/07/11/deploy-operator-gitops-using-advanced-cluster-management"&gt;how to integrate security policies into a GitOps environment&lt;/a&gt; to apply consistently throughout your clusters. Security policies are part of &lt;a href="https://www.redhat.com/en/technologies/management/advanced-cluster-management"&gt;Red Hat Advanced Cluster Management for Kubernetes&lt;/a&gt;, a platform that helps users configure and deploy applications and other valuable services such as metrics. &lt;/p&gt; &lt;h2&gt;SaaS security&lt;/h2&gt; &lt;p&gt;The most recent article of our series on &lt;a href="https://developers.redhat.com/articles/2022/05/18/saas-architecture-checklist-kubernetes"&gt;building and deploying Software as a service (SaaS) applications&lt;/a&gt; covered &lt;a href="https://developers.redhat.com/articles/2022/07/27/saas-security-kubernetes-environments-layered-approach"&gt;SaaS security for containers in Kubernetes environments&lt;/a&gt;. Within modern enterprise environments, it's critical to build security into the full life cycle of planning, development, operations, and maintenance.&lt;/p&gt; &lt;p&gt;Keep an eye out for future installments covering &lt;a href="https://developers.redhat.com/topics/automation"&gt;automation&lt;/a&gt; for SaaS development, scalability and disaster recovery, and more.&lt;/p&gt; &lt;h2&gt;Integrate Infinispan and ASP.NET Core&lt;/h2&gt; &lt;p&gt;The open source Infinispan data store is a popular option for in-memory operations. &lt;a href="https://developers.redhat.com/topics/dotnet/"&gt;ASP.NET Core&lt;/a&gt; applications can now easily integrate Infinispan as a caching service or session provider. Vittorio Rigamonti provides answers on how to do that in &lt;a href="https://developers.redhat.com/topics/c/"&gt;C#&lt;/a&gt; on &lt;a href="https://developers.redhat.com/topics/linux/"&gt;Linux&lt;/a&gt; in his article &lt;a href="https://developers.redhat.com/articles/2022/07/07/add-infinispan-cache-your-aspnet-application"&gt;Add an Infinispan cache to your ASP.NET application&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Go Toolset container images&lt;/h2&gt; &lt;p&gt;Red Hat's Go Toolset package is available as a container image and offers developers a kickstart to building modern Go applications. It delivers the Go language with Federal Information Processing Standard (FIPS) support for cryptographic modules and the Delve debugger to &lt;a href="https://developers.redhat.com/products/rhel/overview"&gt;Red Hat Enterprise Linux&lt;/a&gt; customers.&lt;/p&gt; &lt;p&gt;In &lt;a href="https://developers.redhat.com/articles/2022/07/21/how-use-go-toolset-container-images"&gt;How to use Go Toolset container images&lt;/a&gt;, Alejandro Sáez Morollón illustrates how these images support modern Go development and make you more productive in the cloud.&lt;/p&gt; &lt;h2&gt;Secure secrets on Kubernetes &lt;/h2&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/2019/08/15/how-to-use-dekorate-to-create-kubernetes-manifests/"&gt;Dekorate&lt;/a&gt; is a tool that simplifies the process of generating cert-manager custom resources. You can use it to create secrets, such as encryption keys and passwords for your Spring Boot application.&lt;/p&gt; &lt;p&gt;Read &lt;a href="https://developers.redhat.com/articles/2022/07/19/secure-kubernetes-certificates-cert-manager-and-dekorate"&gt;Secure Kubernetes certificates with cert-manager and Dekorate&lt;/a&gt; and learn how to keep your secrets safe while developing or running production applications.&lt;/p&gt; &lt;h2&gt;July 2022 on Red Hat Developer&lt;/h2&gt; &lt;p&gt;Here's the full lineup of articles published on Red Hat Developer this month:&lt;/p&gt; &lt;ul&gt; &lt;li aria-level="1"&gt;&lt;a href="https://developers.redhat.com/articles/2022/07/27/saas-security-kubernetes-environments-layered-approach"&gt;SaaS security in Kubernetes environments: A layered approach&lt;/a&gt;&lt;/li&gt; &lt;li aria-level="1"&gt;&lt;a href="https://developers.redhat.com/articles/2022/07/21/how-use-go-toolset-container-images"&gt;How to use Go Toolset container images&lt;/a&gt;&lt;/li&gt; &lt;li aria-level="1"&gt;&lt;a href="https://developers.redhat.com/articles/2022/07/20/git-workflows-best-practices-gitops-deployments"&gt;Git workflows: Best practices for GitOps deployments&lt;/a&gt;&lt;/li&gt; &lt;li aria-level="1"&gt;&lt;a href="https://developers.redhat.com/articles/2022/07/19/secure-kubernetes-certificates-cert-manager-and-dekorate"&gt;Secure Kubernetes certificates with cert-manager and Dekorate&lt;/a&gt;&lt;/li&gt; &lt;li aria-level="1"&gt;&lt;a href="https://developers.redhat.com/articles/2022/07/18/simplify-client-connection-configurations-service-contexts"&gt;Connect to OpenShift application services with contexts&lt;/a&gt;&lt;/li&gt; &lt;li aria-level="1"&gt;&lt;a href="https://developers.redhat.com/articles/2022/07/15/new-http-clients-java-generator-and-more-fabric8-600"&gt;New HTTP clients, a Java generator, and more in Fabric8 6.0.0&lt;/a&gt;&lt;/li&gt; &lt;li aria-level="1"&gt;&lt;a href="https://developers.redhat.com/articles/2022/07/14/kafka-monthly-digest-june-2022"&gt;Kafka Monthly Digest: June 2022&lt;/a&gt;&lt;/li&gt; &lt;li aria-level="1"&gt;&lt;a href="https://developers.redhat.com/articles/2022/07/07/add-infinispan-cache-your-aspnet-application"&gt;Add an Infinispan cache to your ASP.NET application&lt;/a&gt;&lt;/li&gt; &lt;li aria-level="1"&gt;&lt;a href="https://developers.redhat.com/articles/2022/07/06/deploy-jboss-eap-microsoft-azure-red-hat-openshift"&gt;Deploy JBoss EAP on Microsoft Azure Red Hat OpenShift&lt;/a&gt;&lt;/li&gt; &lt;li aria-level="1"&gt;&lt;a href="https://developers.redhat.com/articles/2022/07/06/what-qualifies-red-hat-developer-subscription-teams"&gt;What qualifies for Red Hat Developer Subscription for Teams?&lt;/a&gt;&lt;/li&gt; &lt;li aria-level="1"&gt;&lt;a href="https://developers.redhat.com/articles/2022/07/05/debugging-hedy-and-nostalgia-3-talks-openjs-world-2022"&gt;Debugging, Hedy, and nostalgia: 3 talks at OpenJS World 2022&lt;/a&gt;&lt;/li&gt; &lt;li aria-level="1"&gt;&lt;a href="https://developers.redhat.com/articles/2022/07/05/write-systemtap-script-trace-code-execution-linux"&gt;Write a SystemTap script to trace code execution on Linux&lt;/a&gt;&lt;/li&gt; &lt;li aria-level="1"&gt;&lt;a href="https://developers.redhat.com/articles/2022/07/13/install-storage-your-application-cluster-using-rook"&gt;Install storage in your application cluster using Rook&lt;/a&gt;&lt;/li&gt; &lt;li aria-level="1"&gt;&lt;a href="https://developers.redhat.com/articles/2022/07/12/how-run-vs-code-openshift-dev-spaces"&gt;How to run VS Code with OpenShift Dev Spaces&lt;/a&gt;&lt;/li&gt; &lt;li aria-level="1"&gt;&lt;a href="https://developers.redhat.com/articles/2022/07/11/deploy-operator-gitops-using-advanced-cluster-management"&gt;Deploy an Operator via GitOps using Advanced Cluster Management&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/07/29/red-hat-developer-roundup-best-july-2022" title="Red Hat Developer roundup: Best of July 2022"&gt;Red Hat Developer roundup: Best of July 2022&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Heiker Medina</dc:creator><dc:date>2022-07-29T07:00:00Z</dc:date></entry><entry><title type="html">Keycloak 19.0.1 released</title><link rel="alternate" href="https://www.keycloak.org/2022/07/keycloak-1901-released" /><author><name /></author><id>https://www.keycloak.org/2022/07/keycloak-1901-released</id><updated>2022-07-29T00:00:00Z</updated><content type="html">To download the release go to . MIGRATION FROM 18.0 Before you upgrade remember to backup your database. If you are not on the previous release refer to for a complete list of migration changes. ALL RESOLVED ISSUES BUGS * Set `resourcesVersionSeed` when using ConcurrentHashMap storage keycloak storage * Installation error - You have an error in your SQL syntax keycloak dist/quarkus * Documentation fixes in configuring keycloak page keycloak dist/quarkus UPGRADING Before you upgrade remember to backup your database and check the for anything that may have changed.</content><dc:creator /></entry><entry><title type="html">Efesto refactoring &amp;#8211; Introduction</title><link rel="alternate" href="https://blog.kie.org/2022/07/efesto-refactoring-introduction.html" /><author><name>Gabriele Cardosi</name></author><id>https://blog.kie.org/2022/07/efesto-refactoring-introduction.html</id><updated>2022-07-28T07:10:46Z</updated><content type="html">This post is meant as an introduction of the overall motivations, goals and choices around the Efesto initiative. PREMISE Originally, "Drools" (and its repository) was meant only as a "rule engine", and all the code was built around this paradigm. Over the years, new engines have been created that used, more or less, the "rule engine", or even not at all. That changed completely the actual paradigm, but the code did not reflected such a change. Different solutions or workarounds have been put in place to make this two incompatible realities (a code meant to invoke mainly the "rule engine", on one side, and different engines interacting in a coordinate manner, on the other side) works together. One of this attempt was the introduction of the "KieAssembler" (and derived) APIs. The goal was to provide a way to coordinate the execution of the different engines, but unfortunately the implementation had two flaws: * its execution has been inserted inside the code flow that was originally written for the rule engine; * it has not been adapted by all the engines, but only by the ones developed after its introduction. The result of the above is that what was meant as "coordinator" of all the different engines, became a specific sub-path of execution of the rules one; and the path of execution of the rules became, as a matter of fact, the coordinator of all the other engines. Beside that, for reasons specific to the "rule engine", the separation of a "compilation" phase and an "execution" one has never been strongly enforced, and this lack of separation leaked in the codebase. The post provides details of an analogue work done inside the Rule engine itself, showing the complexity of the task to be faced. These issues made the code hard to maintain and to expand, requiring a lot of ad-hoc solutions for problems that, actually, are inherent to the whole system. The "KieAssembler" clearly shows that. The engines that extend it have to implement the methods needed for both the compilation and the execution phase; and those KieAssembler-extending classes are invoked both at compile-time and at runtime-phase. As an example, the currently available version of tries to enforce a kind of separation with two different utility classes: * * Again, this is a downstream workaround for a design flaw. As such, each engine should write similar workarounds, and that would not solve the root cause. Consequence of that is that different engines follows different designs and address the same needs in different ways. Some attempts have been made to address these shortcomings, but at a downstream level, and for a more or less specific use-case, making those attempts less efficient then expected. The best example of this is the project. The goal of the "Efesto" refactoring is to tackle all the mentioned issues at the root, adapting the overall codebase to the current paradigm by which the different components are used, following the hard lessons learned over the years. DICTIONARY We define a domain dictionary here because, over the years, some terms have been used with different meanings in different situations, and almost always misunderstanding arose due to these different interpretations. The following are the definition and meanings used in this series of posts: * Model: the textual representation of a given model; e.g. Rules (DRL, other), Decision (DMN), Predictions (PMML), Workflow (BPMN, other) * Engine: the code needed to * transform a specific model in executable form; * execute the executable form of a specific model with a given input data * some examples: * Rule engine * Decision engine * Prediction engine * Workflow engine * Efesto: the framework that exposes the functionalities of the different engines and the name of the project that contains the refactoring * Compile-time: the process of transform the original model in executable form * Runtime: the process of executing a given model with a user input * Container: a given application that uses the drools functionalities (compilation and/or runtime) to fulfill its scope; some examples: * Kie-maven-plugin: uses compile-time to retrieve bytecode and then dump it to a kjar; * Kie-server: uses runtime to load/execute kjars (and, eventually, compile-time for on-the-fly compilation/reload) * Kogito-build: uses compile-time to retrieve bytecode and then dump it to a jar/native image; * Kogito-execution: uses runtime to load/execute jar/native image CLEAN ARCHITECTURE PRINCIPLES The main goal is to have a modular, decoupled system that will be easy to maintain in the long term (i.e. fixing bugs, improving performance, adding features). To achieve that, the knowledge relationship between the different parts is clearly defined and enforced. The system has core components and peripheral components. The “knowledge” arrow points only inward, i.e. peripheral components have knowledge of core components, but not the other way around. Peripheral components does not have knowledge of each other. MICROKERNEL STYLE The microkernel/plugin design is used to reflect the relationship between the different engines and the overall system. Every engine is implemented as a plugin component, and no direct relationship exists between plugins. MAIN TASKS The goal of Efesto refactoring are: * Separate what is “Drools” and what is not Drools * Separate compilation/execution phases * Enforce engines consistency * Provide a pluggable/chainable design SEPARATE DROOLS/NOT DROOLS Efesto (the framework, as defined in this post) is considered an agnostic provider of model execution. As such, it does not depend on any other framework, and it is available as a standalone library, runnable inside any kind of environment/container (e.g. Spring, Quarkus, Kogito, KieServer, etc). To allow that, it contains the bare-minum code required to coordinate the transformation of models in unit of executions, and the execution of them to provide a result. One consequence of this approach is that some functionalities, that are currently in charge of the drools code, will be delegated to the "container". As example, the framework does not write compiled classes to the filesystem, but delegates this task to the invoking code, like the KieMaven plugin. The reason behind this specific choice is that write to a filesystem, and relying on that, requires a series of assumptions (firt of all, a read-write environment) that are not absolutely granted, and should not be addressed by the framework itself, but by the container it is used in. SEPARATE COMPILATION/EXECUTION PHASES As defined before, compilation is the process of transforming a model to an executable unit. Usually it involves some code-generation, but this is not mandatory at all. The result of a compilation is stored inside a so-called "IndexFile", that is a registry of the generated resources, and also contains the entry-point for the execution. As a matter of fact, this entry-point could be a code-generated class, but also an already-existing one (e.g. DMN). On the other side, execution is the process of receiving input data, submitting it to unit of execution, and returning a result. In this phase, the framework reads the identifier of the resource to be invoked from the input; then, the required engine reads the informations needed for the invocation of the entry point from the IndexFile. ENFORCE ENGINES CONSISTENCY Every engine follows the same design. This means that inside the Drools framework there is not a preferential path of execution, tailored around one specific engine, to which all the others have to adapt. Instead, they all implements the same common API, so that the flow of execution is the same for every one. At the same time, this requires and enforces independency between the engines. Every engine implements a “compilation” service and a “loading” service: the former responsible of compiled-resource generation (e.g. code-generation, class compilation, entry-point definition); the latter responsible for actual entry-point invocation. PROVIDE A PLUGGABLE/CHAINABLE DESIGN The microkernel architecture allows the implementation of different engines as isolated plugins. That, in turns, provides some out-of-the-box features: * parallel development of different engines, avoiding overlapping/conflict issues * incremental implementation of new engines, without the needs of a BigBang release * no Monolithic design, where every component is bound, directly on indirectly, to the others * different implementation for the same engine, delegating the choice to the container (with the maven dependency mechanism) * allows “customer” to implement their own version/customization for a given engine The "chainable" feature refers to the possibility to invoke one engine from another. This is a well-known requirement at execution time (e.g. DMN engine requires PMML engine evaluation), but also at compile-time. Since part of execution could be delegated to another engine, this implies that the invoked engine should have "compiled" that part of execution (whatever this mean in specific cases). Another interesting use case is to compile different resources to the same engine. An example of this is offered by Rule engine. THE RULE ENGINE USE-CASE The Rule engine actually has different "formats": Drl files, Decision tables, etc.. All this models are "translated" to a PackageDescr at a given point; and the final result is always the same, an Executable model. For each kind of source there is a specific implementation responsible to translate it to a PackageDescr. There is also an implementation that takes as input the PackageDescr and returns the Executable model. So, the different model-specific engines translates the input to a PackageDescr, and then delegates to the latter one to transform it to the final Executable model. As a by-side note, that chainability feature provides an extremely easy and fast way to manage any kind of "definition" as "Rules" (or whatever engine). CONCLUSION This is the first post of a series around the Efesto effort and implementation. Following ones will go deeper inside technical details and will provide some real use-cases and code so… stay tuned!!! The post appeared first on .</content><dc:creator>Gabriele Cardosi</dc:creator></entry><entry><title type="html">This Week in JBoss - July 28th 2022</title><link rel="alternate" href="https://www.jboss.org/posts/weekly-2022-07-28.html" /><category term="quarkus" /><category term="java" /><category term="kubernetes" /><category term="openshift" /><category term="dekorate" /><category term="operators" /><category term="gitops" /><category term="security" /><category term="fabric8" /><category term="jfr" /><category term="performance" /><category term="monitoring" /><category term="jvm" /><author><name>Stefan Sitani</name><uri>https://www.jboss.org/people/stefan-sitani</uri><email>do-not-reply@jboss.com</email></author><id>https://www.jboss.org/posts/weekly-2022-07-28.html</id><updated>2022-07-28T00:00:00Z</updated><content type="html">&lt;article class="" data-tags="quarkus, java, kubernetes, openshift, dekorate, operators, gitops, security, fabric8, jfr, performance, monitoring, jvm"&gt; &lt;h1&gt;This Week in JBoss - July 28th 2022&lt;/h1&gt; &lt;p class="preamble"&gt;&lt;/p&gt;&lt;p&gt;Hello, everyone. Welcome to the latest edition of &lt;em&gt;This Week in JBoss&lt;/em&gt;. We are in the middle of summer, but our favorite projects keep coming up with cool new releases, dev tips, and demos. Take a look at the JBoss community content highlights from the past 2 weeks.&lt;/p&gt;&lt;p&gt;&lt;/p&gt; &lt;div class="sect1"&gt; &lt;h2 id="_releases_releases_releases"&gt;Releases, releases, releases!&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;Here are the releases from the JBoss Community for this edition:&lt;/p&gt; &lt;div class="ulist square"&gt; &lt;ul class="square"&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://camel.apache.org/blog/2022/07/camel-quarkus-release-2.11.0"&gt;Camel Quarkus 2.11.0&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://debezium.io/releases/2.0/"&gt;Debezium 2.0.0 Beta 1&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://docs.drools.org/7.73.0.Final/drools-docs/html_single/index.html"&gt;Drools 7.73.0&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://blog.marcnuri.com/fabric8-kubernetes-client-6-0-0"&gt;Fabric8 Kubernetes Client 6.0.0&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://www.keycloak.org/2022/07/keycloak-1901-released"&gt;Keycloak 19.0.1&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://www.optaplanner.org/download/releaseNotes/releaseNotes8.html"&gt;OptaPlanner 8.25.0&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://quarkus.io/blog/quarkus-2-11-1-final-released/"&gt;Quarkus 2.11.1 and Quarkus 2.10.4&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://resteasy.dev/2022/07/21/resteasy-releases/#"&gt;RESTEasy 6.0.3, 5.0.4, and 4.7.7&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://strimzi.io/blog/2022/07/27/what-is-new-in-strimzi-0.30.0/"&gt;Strimzi 0.30.0&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://www.wildfly.org/downloads/"&gt;WildFly 27 Alpha 3&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_articles_blogs"&gt;Articles &amp;#38; Blogs&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="sect2"&gt; &lt;h3 id="_secure_kubernetes_certificates_with_cert_manager_and_dekorate"&gt;Secure Kubernetes certificates with cert-manager and Dekorate&lt;/h3&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/articles/2022/07/19/secure-kubernetes-certificates-cert-manager-and-dekorate"&gt;Secure Kubernetes certificates with cert-manager and Dekorate&lt;/a&gt; by Jose Carvajal Hilario, Anna-Maria Mihalceanu, and Charles Moulliard.&lt;/p&gt; &lt;p&gt;Managing SSL certificates for your cloud native apps can sometimes get a little tricky. &lt;a href="https://cert-manager.io/"&gt;Cert-manager&lt;/a&gt;, a popular tool for cloud-native certificate management helps makes this task a lot easier. But before they can start using it, developers need to deal with creating custom resources that cert-manager requires. Enter &lt;a href="https://dekorate.io/"&gt;Dekorate&lt;/a&gt;, the tool that significantly decreases the complexity of managing custom resource for Kubernetes and OpenShift. This walkthrough demonstrates how Dekorate automatically creates cert-manager custom resources from annotations in your code. You can then install these resources in a project on your cluster and use them to secure the REST endpoints of your application with TLS. The article provides rich code examples for every step, and also an example application project based on Spring Boot that you can use to follow along with the walkthrough.&lt;/p&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="_new_http_clients_a_java_generator_and_more_in_fabric8_6_0_0"&gt;New HTTP clients, a Java generator, and more in Fabric8 6.0.0&lt;/h3&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/articles/2022/07/15/new-http-clients-java-generator-and-more-fabric8-600"&gt;New HTTP clients, a Java generator, and more in Fabric8 6.0.0&lt;/a&gt; by Andrea Peruffo and Steven Havwkins&lt;/p&gt; &lt;p&gt;The Fabric8 Kubernetes client has been making cloud-native development with Java easier for years. After more than five months of intensive work, the release of Fabric8 6.0.0 brings a host of innovative features and capabilities to the core components and utilities in the Fabric8 suite. Steven Hawkins and Andrea Peruffo show off some the coolest features and important bugfixes that the new release has to offer. Check out their article to see the highlights&lt;/p&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="_how_to_use_java_mission_control_to_monitor_java_apps"&gt;How to use Java Mission Control to monitor Java apps&lt;/h3&gt; &lt;p&gt;&lt;a href="http://www.mastertheboss.com/java/how-to-use-java-mission-control-to-monitor-java-apps/"&gt;How to use Java Mission Control to monitor Java apps&lt;/a&gt; by Francesco Marchioni&lt;/p&gt; &lt;p&gt;Those of you with an interest in monitoring the performance of your Java apps will find Francesco’s post especially informative. The article focuses on Java Flight Recorder (JFR), a JVM monitoring tool that also powers the recently released &lt;a href="https://cryostat.io/"&gt;Cryostat&lt;/a&gt; project. In addition to offering insights into the JFR user experience compared to competing tools like JConosle and VisualVM (which he covered in earlier articles), Francesco also provides a quickstart guide for spinning up JFR with Java Mission Control to monitor a Wildfly server.&lt;/p&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="_saas_security_in_kubernetes_environments_a_layered_approach"&gt;SaaS security in Kubernetes environments: A layered approach&lt;/h3&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/articles/2022/07/27/saas-security-kubernetes-environments-layered-approach#"&gt;SaaS security in Kubernetes environments: A layered approach&lt;/a&gt; by Alex Kubacki&lt;/p&gt; &lt;p&gt;In his most recent article, Alex Kubacki analyzes recommended practices for securing software-as-a-service applications. Opening with the argument that if you want to truly secure your applications, you must secure every layer of your application stack (all the way from the hardware to the container network interface), Alex moves on to break down the security concerns specific to each layer. He gives particular attention to the cluster and networking layers, where he highlights the benefits of recently released projects, including Advanced Cluster Security for Kubernetes and the more recent networking security innovations in OpenShift.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_videos"&gt;Videos&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;Since we are in middle of vacation season, there isn’t as much new content coming out as the rest of the year. Still, there is definitely enough to choose from. Please enjoy this week’s video picks:&lt;/p&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://youtu.be/kdasoBPOWUQ"&gt;Quarkus Insights #96: Quarkus Q&amp;#38;A&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://"&gt;Kube by Example #13 with Travis Nielsen&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://youtu.be/1K92tit2uCk"&gt;Demo: &lt;em&gt;Encrypting an Elytron Filesystem Realm&lt;/em&gt; by Ashpan Raskar&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;p&gt;&lt;em&gt;That’s all for today! Please stay tuned for the next editorial, stay safe, and enjoy the rest of the vacation season!&lt;/em&gt;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="author"&gt; &lt;pfe-avatar pfe-shape="circle" pfe-pattern="squares" pfe-src="/img/people/stefan-sitani.png"&gt;&lt;/pfe-avatar&gt; &lt;span&gt;Stefan Sitani&lt;/span&gt; &lt;/div&gt;&lt;/article&gt;</content><dc:creator>Stefan Sitani</dc:creator></entry><entry><title type="html">How to run Java Mission Control in Eclipse</title><link rel="alternate" href="http://www.mastertheboss.com/java/how-to-run-java-mission-control-in-eclipse/" /><author><name>F.Marchioni</name></author><id>http://www.mastertheboss.com/java/how-to-run-java-mission-control-in-eclipse/</id><updated>2022-07-27T15:02:27Z</updated><content type="html">This article continues our learning through the Java Mission Control (JMC) tool. Within it, we will learn how to run JMC as standalone application or as Eclipse IDE plugin. Firstly, if you are new to Java Mission Control, we recommend checking this article for a brief introduction to it: How to use Java Mission Control ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry><entry><title>SaaS security in Kubernetes environments: A layered approach</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/07/27/saas-security-kubernetes-environments-layered-approach" /><author><name>Alex Kubacki</name></author><id>265fb1fc-a3c2-44d1-a2d0-41d140c6ac79</id><updated>2022-07-27T07:00:00Z</updated><published>2022-07-27T07:00:00Z</published><summary type="html">&lt;p&gt;&lt;a href="https://developers.redhat.com/topics/security/"&gt;Security&lt;/a&gt; is especially critical for &lt;a href="https://www.redhat.com/en/topics/cloud-computing/what-is-saas"&gt;Software-as-a-Service (SaaS)&lt;/a&gt; environments, where the platform is used by many different people who need the confidence that their data is stored safely and kept private from unrelated users. This article focuses on security concerns for &lt;a data-entity-substitution="canonical" data-entity-type="node" data-entity-uuid="4093cbb4-5a74-4678-9a7a-7e3d9c8b81c1" href="https://developers.redhat.com/topics/containers" title="Building containerized applications"&gt;containers&lt;/a&gt; on your SaaS deployment running in &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt; environments such as &lt;a href="https://developers.redhat.com/openshift"&gt;Red Hat OpenShift&lt;/a&gt;. The article is the fifth in a series called the &lt;a href="https://developers.redhat.com/articles/2022/05/18/saas-architecture-checklist-kubernetes"&gt;SaaS architecture checklist&lt;/a&gt; that covers the software and deployment considerations for SaaS applications.&lt;/p&gt; &lt;h2&gt;Security controls and practices for SaaS&lt;/h2&gt; &lt;p&gt;Within modern enterprise environments, security needs to be built into the full life cycle of planning, development, operations, and maintenance. Good security controls and practices are critical to meeting compliance and regulatory requirements and making sure that transactions are reliable and high-performing. Security in SaaS can be broken down into five main layers: hardware, operating system, containers, Kubernetes, and networking. Figure 1 shows these layers and the security controls that address threats at each layer.&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/layers.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/layers.png?itok=5BHUmoFN" width="478" height="829" alt="SaaS layers and their security features in Kubernetes and OpenShift." loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 1: SaaS layers and their security features in Kubernetes and OpenShift.&lt;/figcaption&gt; &lt;/figure&gt; &lt;p&gt;Security needs to be addressed at every layer because any vulnerability in one layer could be exploited to compromise other layers. For each layer, Kubernetes and OpenShift have security controls and features that will be covered in this article. Future articles will go into more detail on specific SaaS security topics. If there are any SaaS topics for which you would like to see an article, let us know in the comments.&lt;/p&gt; &lt;h2&gt;Security at the hardware layer&lt;/h2&gt; &lt;p&gt;Securing a SaaS environment often starts with identifying where the application is going to run and the security concerns for that environment. A secure environment includes the actual data center as well as the hardware itself, including disk encryption, secure boot, BIOS-level passwords, and the use of hardware security modules (HSMs). Secrets and identity management are discussed later in this article.&lt;/p&gt; &lt;p&gt;While a lot of attention is paid to using encryption to protect &lt;em&gt;data in transit&lt;/em&gt; as it goes over the network, it is also critical to protect &lt;em&gt;data at rest&lt;/em&gt; as it is stored on physical storage devices in data centers. The risks to data at rest are much higher in data centers where you lack control over access to the facility and where third-party contractors may be employed. Use disk encryption to secure data at rest by protecting the data stored on the physical server from unintended access.&lt;/p&gt; &lt;p&gt;An HSM is typically a physical device that securely stores digital keys through encryption to protect sensitive data. HSMs are used to manage and safeguard security credentials, keys, certificates, and secrets while at rest and in transit. The HSM provides an increased level of protection over software-only approaches such as a secrets vault.&lt;/p&gt; &lt;p&gt;Cloud HSMs are available from the major cloud providers to provide increased protection in cloud environments. HSMs are recommended to manage secrets in SaaS environments.&lt;/p&gt; &lt;p&gt;Protect access to the server by enabling secure boot and using BIOS-level passwords. Secure boot is a firmware security feature of the Unified Extensible Firmware Interface (UEFI) that makes sure that only immutable and signed software can be run during boot.&lt;/p&gt; &lt;p&gt;For more information, check out:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://www.redhat.com/en/blog/identity-and-access-devsecops-life-cycle"&gt;Identity and access in the DevSecOps life cycle&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://cloud.redhat.com/blog/self-contained-ready-and-secured-enhancing-red-hat-openshift-with-hardware-cryptography"&gt;Enhancing Red Hat OpenShift with Hardware Cryptography&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/security_hardening/assembly_securing-rhel-during-installation-security-hardening#BIOS_and_UEFI_security_securing-rhel-during-installation"&gt;Securing Red Hat Enterprise Linux during installation&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Operating system security&lt;/h2&gt; &lt;p&gt;Every Kubernetes cluster runs on top of some underlying operating system (OS). Security features and hardening at the OS layer help protect the overall cluster, so it is important to enable and use OS-level controls.&lt;/p&gt; &lt;p&gt;When it comes to security hardening at the OS level, Red Hat OpenShift has two distinct advantages. First, &lt;a href="https://www.redhat.com/en/topics/linux/what-is-selinux"&gt;Security-Enhanced Linux&lt;/a&gt; (SELinux) is integrated and enabled out of the box. Second, OpenShift runs on Red Hat Enterprise Linux CoreOS, a unique OS image tuned for SaaS use.&lt;/p&gt; &lt;h3&gt;Security-enhanced Linux&lt;/h3&gt; &lt;p&gt;SELinux is a security architecture for &lt;a href="https://developers.redhat.com/topics/linux/"&gt;Linux&lt;/a&gt; systems that grants administrators finer-grained control over access to system resources than is available with default Linux. SELinux defines mandatory access controls for applications, processes, and files on a system. On a Kubernetes node, SELinux adds an important layer of protection against &lt;a href="https://www.redhat.com/en/blog/latest-container-exploit-runc-can-be-blocked-selinux"&gt;container-breakout vulnerabilities&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Thus, one of the most effective security measures is to enable and configure SELinux, which Red Hat has made standard on all OpenShift clusters. It is considered a best practice to use SELinux in SaaS environments. In OpenShift, SELinux enhances container security by ensuring true container separation and mandatory access control.&lt;/p&gt; &lt;p&gt;For more information, see:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://www.redhat.com/en/blog/how-selinux-separates-containers-using-multi-level-security"&gt;How SELinux separates containers using Multi-Level Security&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://www.redhat.com/en/blog/why-you-should-be-using-multi-category-security-your-linux-containers"&gt;Why you should be using Multi-Category Security for your Linux containers&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://www.redhat.com/en/blog/using-container-technology-make-trusted-pipeline"&gt;Using container technology to make a more secure pipeline&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://www.redhat.com/en/blog/network-traffic-control-containers-red-hat-openshift"&gt;Network traffic control for containers in Red Hat OpenShift&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;h3&gt;A hardened OS for containers: Red Hat Enterprise Linux CoreOS&lt;/h3&gt; &lt;p&gt;OpenShift's operating system, Red Hat Enterprise Linux CoreOS, is based on Red Hat Enterprise Linux and uses the same kernel, code, and open source development processes. This special version ships with a specific subset of Red Hat Enterprise Linux packages, designed for use in OpenShift 4 clusters. The key features that make this operating system more secure are:&lt;/p&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;Based on Red Hat Enterprise Linux: The underlying OS is primarily Red Hat Enterprise Linux components, which means it has the same quality, security, control measures, and support. When a fix is pushed to Red Hat Enterprise Linux, that same fix is pushed to Red Hat Enterprise Linux CoreOS.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Controlled immutability: Red Hat Enterprise Linux CoreOS is managed via OpenShift APIs, which leads to more hands-off operating system management. Management is primarily performed in bulk for all nodes throughout the OpenShift cluster. The latest state of the Red Hat Enterprise Linux CoreOS system is stored on the cluster, making it easy to add new nodes or push updates to all nodes. Given the OS's centralized management and transactional nature, only a few system settings can be modified on a Red Hat Enterprise Linux CoreOS installation.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Command-line container tools: Red Hat Enterprise Linux CoreOS includes container tools compatible with the &lt;a href="https://opencontainers.org"&gt;Open Container Initiative&lt;/a&gt; (OCI) specification to build, copy, and manage container images. Many container runtime administration features are available through Podman. The &lt;a href="https://www.redhat.com/sysadmin/how-run-skopeo-container"&gt;skopeo&lt;/a&gt; command copies, authenticates, and signs images. The &lt;a href="https://kubernetes.io/docs/tasks/debug/debug-cluster/crictl/"&gt;crictl&lt;/a&gt; command lets you view and troubleshoot containers and pods.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Robust transactional updates: Red Hat Enterprise Linux CoreOS offer the &lt;a href="https://coreos.github.io/rpm-ostree/"&gt;rpm-ostree&lt;/a&gt; upgrade process, which assures that an upgrade takes place atomically. If something goes wrong, the original OS can be restored in a single rollback.&lt;/p&gt; &lt;p&gt;OpenShift handles OS upgrades through the &lt;a href="https://github.com/openshift/machine-config-operator"&gt;Machine Config Operator&lt;/a&gt; (MCO), which encompasses a complete OS upgrade instead of individual packages as in traditional Yum upgrades. OpenShift also updates nodes via a rolling update to mitigate the updates' impact and maintain cluster capacity. During installation and upgrades, the latest immutable filesystem tree is read from a container image, written to disk, and loaded to the bootloader. The machine will reboot into the new OS version, guaranteeing an atomic update.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;Security during cluster installation: Red Hat Enterprise Linux CoreOS minimizes security decisions during installation. Two security features are considered pre-first boot decisions for cluster operations: &lt;a href="https://docs.openshift.com/container-platform/4.8/installing/installing-fips.html#installing-fips"&gt;support for FIPS cryptography&lt;/a&gt; and full disk encryption (FDE). After the cluster is bootstrapped, the cluster can further be configured for other node-level changes.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Container layer&lt;/h2&gt; &lt;p&gt;The container layer in Kubernetes and OpenShift isolates processes from one another and from the underlying OS. Instead of traditional software design, where all the components are linked, deployed together, and ultimately dependent on each other, containers are independent, resulting in smaller impacts. If one container goes down, it can easily be replaced. If a container image is found to have a security flaw, the flaw is isolated to that image and requires updating only that image rather than the whole cluster.&lt;/p&gt; &lt;p&gt;Red Hat OpenShift has many features that improve container security for multitenant environments.&lt;/p&gt; &lt;h3&gt;Container engine&lt;/h3&gt; &lt;p&gt;A &lt;em&gt;container engine&lt;/em&gt; provides tools for creating container images and starting containers. In OpenShift, the default container engine is &lt;a href="https://docs.openshift.com/container-platform/3.11/crio/crio_runtime.html"&gt;CRI-O&lt;/a&gt;, which supports containers conforming to OCI and libcontainerd. The container engine focuses on the features needed by Kubernetes's &lt;a href="https://kubernetes.io/docs/concepts/architecture/cri/"&gt;Container Runtime Interface&lt;/a&gt; (CRI). This customized container engine shrinks the surface available to a security attack, because the container engine does not contain unneeded features such as direct command-line use or orchestration facilities.&lt;/p&gt; &lt;p&gt;We have also aligned the CRI more with Kubernetes: Updates to CRI-O are made to work better with the current Kubernetes release.&lt;/p&gt; &lt;h3&gt;Container security in the Linux kernel&lt;/h3&gt; &lt;p&gt;The kernel offers features to ensure the security of containers and everything else running on the OS. First off, all containers are launched inside a namespace that creates an isolated sandbox segregating the containers, files systems, processes, and networking.&lt;/p&gt; &lt;p&gt;The next feature is &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/resource_management_guide/ch01"&gt;control groups&lt;/a&gt; (cgroups), which isolate hardware resource sharing between containers and nodes of the OpenShift cluster. The use of cgroups prevents any single process or container from using up all the available resources on a host.&lt;/p&gt; &lt;p&gt;Finally, as we discussed earlier, Red Hat Enterprise Linux CoreOS enables SELinux, which prevents a container from breaking its isolation and thus interfering indirectly with other containers on the same host.&lt;/p&gt; &lt;h2&gt;Cluster security on Kubernetes and Red Hat OpenShift&lt;/h2&gt; &lt;p&gt;The cluster level controls how Kubernetes deploys hosts, manages shared resources, controls intercontainer communications, manages scaling, and controls access to the cluster. An OpenShift cluster is made up of a control plane, worker nodes, and any additional resources needed. The following subsections cover some of the security concerns for the different aspects of the cluster.&lt;/p&gt; &lt;h3&gt;Control plane isolation&lt;/h3&gt; &lt;p&gt;It is considered a best practice to isolate the cluster's control plane nodes from the worker nodes. This is usually done using separate hardware for the control plane to mitigate the impact of any misconfiguration, resource management problems, or vulnerabilities.&lt;/p&gt; &lt;h3&gt;Identity management&lt;/h3&gt; &lt;p&gt;Every Kubernetes cluster needs some form of identity management. Out of the box, Red Hat OpenShift comes with a default &lt;a href="https://oauth.net"&gt;OAuth&lt;/a&gt; provider, which is used for token-based authentication. This provider has a single &lt;code&gt;kubeadmin&lt;/code&gt; user account, which you can use to &lt;a href="https://docs.openshift.com/container-platform/4.10/authentication/understanding-identity-provider.html"&gt;configure an identity provider via a custom resource (CR)&lt;/a&gt;. OpenShift supports &lt;a href="https://openid.net/connect/"&gt;OpenID Connect&lt;/a&gt; and LDAP standard identity providers. After identities are defined, use role-based access control (RBAC) to define and apply permissions.&lt;/p&gt; &lt;h3&gt;Cluster access control&lt;/h3&gt; &lt;p&gt;Before users interact with the cluster, they first must authenticate via the OAuth server. Internal connections to the API server are authenticated using X.509 certificates.&lt;/p&gt; &lt;h3&gt;Security context constraints&lt;/h3&gt; &lt;p&gt;&lt;a href="https://docs.openshift.com/container-platform/4.8/authentication/managing-security-context-constraints.html"&gt;Security context constraints&lt;/a&gt; (SCCs) are an OpenShift security feature that limits a pod's resource access and allowable actions. SCCs let administrators control much of the pod's configuration, such as the SELinux context of a container, whether a pod can run privileged containers, and the use of host directories as volumes. In OpenShift, SCCs are enabled by default and cannot be disabled. SCCs can improve isolation in SaaS deployments and reduce the impact of potential vulnerabilities.&lt;/p&gt; &lt;p&gt;Pod SCCs are determined by the group that the user belongs to as well as the service account, if specified. By default, worker nodes and the pods running on them receive an SCC type of &lt;code&gt;restricted&lt;/code&gt;. This SCC type prevents pods from running as privileged and requires them to run under a UID that is selected at runtime from a preallocated range of UIDs.&lt;/p&gt; &lt;h3&gt;Secrets&lt;/h3&gt; &lt;p&gt;In SaaS deployments, the tenants need to secure their sensitive data on the cluster. This is handled with Secret objects on OpenShift. Secret objects hold sensitive information such as passwords, OCP client configuration files, private source repository credentials, etc. This way of using Secret objects decouples the sensitive content from the pods.&lt;/p&gt; &lt;p&gt;When the sensitive content is needed, it can be mounted to the container via a volume plugin, or the system can use the secrets to perform the action on behalf of the pod. Key properties of secrets include:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Secret data can be created by one entity, such as a configuration tool, and referred to by another, such as an application.&lt;/li&gt; &lt;li&gt;Secret data volumes are backed by temporary file-storage facilities (tmpfs) and never come to rest on a node.&lt;/li&gt; &lt;li&gt;Secret data can be shared within a namespace.&lt;/li&gt; &lt;li&gt;Secret data can &lt;a href="https://docs.openshift.com/container-platform/4.10/security/encrypting-etcd.html"&gt;optionally be encrypted at rest&lt;/a&gt;.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;For more information, read &lt;a href="https://docs.openshift.com/container-platform/4.10/nodes/pods/nodes-pods-secrets.html"&gt;Providing sensitive data to pods&lt;/a&gt;.&lt;/p&gt; &lt;h3&gt;Red Hat Advanced Cluster Security for Kubernetes&lt;/h3&gt; &lt;p&gt;In addition to the standard security features in Red Hat OpenShift, Red Hat offers additional products to enhance the security of the platform. One of those is &lt;a href="https://cloud.redhat.com/products/kubernetes-security"&gt;Red Hat Advanced Cluster Security for Kubernetes&lt;/a&gt; (previously StackRox). Red Hat Advanced Cluster Security for Kubernetes protects your vital applications across the build, deploy, and runtime stages. It deploys in your infrastructure and easily integrates with &lt;a href="https://developers.redhat.com/topics/devops/"&gt;DevOps&lt;/a&gt; tooling and workflows. This integration makes it easy to apply security and compliance policies.&lt;/p&gt; &lt;p&gt;Red Hat Advanced Cluster Security adds to OpenShift's built-in security by improving the following core tenants of security:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Improving &lt;em&gt;visibility&lt;/em&gt; of the environment, so administrators can more easily detect issues as they happen.&lt;/li&gt; &lt;li&gt;&lt;em&gt;Managing vulnerabilities&lt;/em&gt; once they have been identified by deploying fixes via an integrated &lt;a href="https://developers.redhat.com/topics/ci-cd/"&gt;CI/CD&lt;/a&gt; pipeline.&lt;/li&gt; &lt;li&gt;Ensuring &lt;em&gt;compliance&lt;/em&gt; with industry standards and best practices.&lt;/li&gt; &lt;li&gt;Adding robust &lt;em&gt;network segmentation&lt;/em&gt; to restrict network traffic to only the necessary uses.&lt;/li&gt; &lt;li&gt;A &lt;em&gt;risk-based &lt;/em&gt;ranking of each deployment to determine the likelihood of a security risk, helping to ensure that the highest risk deployments get immediate remediation first.&lt;/li&gt; &lt;li&gt;Identifying misconfigurations and evaluating role-based access control (RBAC) access for users via &lt;em&gt;configuration management, &lt;/em&gt;to ensure that the configuration meets best practices.&lt;/li&gt; &lt;li&gt;&lt;em&gt;Runtime detection and response&lt;/em&gt; to automatically identify abnormal actions that could indicate a security breach or misuse of the environment.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;To learn more, see &lt;a href="https://cloud.redhat.com/blog/a-brief-introduction-to-red-hat-advanced-cluster-security-for-kubernetes"&gt;A Brief Introduction to Red Hat Advanced Cluster Security for Kubernetes&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Networking layer&lt;/h2&gt; &lt;p&gt;The networking layer is the outermost layer of a security architecture. The network is where most IT security attacks occur, due to misconfiguration and vulnerabilities. Proper planning and configuration of the network security layer components ensure that the environment is secure. Kubernetes has software-defined networking (SDN) controls that can improve network security in SaaS deployments. Red Hat OpenShift provides additional controls that build on what's available in Kubernetes.&lt;/p&gt; &lt;h3&gt;Network policy&lt;/h3&gt; &lt;p&gt;A network policy controls the traffic between pods by defining the permissions they need in order to communicate with other pods and network endpoints. OpenShift expands on policies by logically grouping components and rules into collections for easy management.&lt;/p&gt; &lt;p&gt;It is worth noting that network policies are additive. Therefore, when you create multiple policies on one or more pods, the union of all rules is applied regardless of the order in which you list them. The resulting pod behavior reflects every allow and deny rule for ingress and egress.&lt;/p&gt; &lt;h3&gt;Container network interface&lt;/h3&gt; &lt;p&gt;In a Kubernetes cluster, by default, pods are attached to a single network and have a single container network interface (CNI). The CNI manages the network connectivity of containers and removes resources when containers are deleted.&lt;/p&gt; &lt;p&gt;Kubernetes uses SDN plugins to implement the CNI. They manage the resources of the network interfaces for new pods. The CNI plugins set up proper networking constructs for pod-to-pod and pod-to-external communication and enforce network policies.&lt;/p&gt; &lt;h3&gt;Openshift networking security features&lt;/h3&gt; &lt;p&gt;OpenShift offers the following additional features and components to secure networks for cloud-native deployments:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Network operations: OpenShift includes a set of operators that manage networking components to enforce best practices and mitigate human errors.&lt;/li&gt; &lt;li&gt;Multiple network interfaces: The Kubernetes default is for all pods to use a single network and a single primary network interface, but with OpenShift, you can configure additional network interfaces. This allows network optimization to improve performance and enhances isolation to improve security.&lt;/li&gt; &lt;li&gt;Ingress security enhancements: OpenShift exposes the cluster to external resources or clients via a &lt;em&gt;route&lt;/em&gt; resource. Routes provide advanced features not found in a standard Kubernetes Ingress controller, including TLS re-encryption, TLS passthrough, and split traffic for blue-green deployments.&lt;/li&gt; &lt;li&gt;Egress security enhancements: While the default OpenShift rule allows all egress traffic to leave the cluster with no restrictions, OpenShift has tools for fine-grained control and filtering of outbound traffic. OpenShift lets you control egress traffic via an &lt;a href="https://docs.openshift.com/container-platform/4.6/networking/openshift_sdn/configuring-egress-firewall.html"&gt;egress firewall&lt;/a&gt;, &lt;a href="https://docs.openshift.com/container-platform/4.6/networking/openshift_sdn/using-an-egress-router.html"&gt;egress routers&lt;/a&gt;, and &lt;a href="https://docs.openshift.com/container-platform/4.7/networking/openshift_sdn/assigning-egress-ips.html"&gt;egress static IP addresses&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;Service mesh: Red Hat OpenShift Service Mesh, based on the &lt;a href="https://istio.io"&gt;Istio&lt;/a&gt; project, adds a transparent layer to existing application network services running in a cluster, allowing complex management and monitoring without requiring changes to the services. The service mesh does this by deploying a sidecar proxy alongside the relevant services to intercept and manage all network communications. With Red Hat OpenShift Service Mesh, you can create a network with the following services: discovery, load balancing, service-to-service authentication, failure recovery, metrics, monitoring, A/B testing, canary releases, rate limiting, access control, and end-to-end authentication.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;For more information, see the &lt;a href="https://www.redhat.com/rhdc/managed-files/cl-openshift-security-guide-ebook-us287757-202103.pdf"&gt;Red Hat OpenShift Security Guide&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Partner with Red Hat to build your SaaS&lt;/h2&gt; &lt;p&gt;This article covered controls that can be used to improve the security of your SaaS deployment at the hardware, OS, container, Kubernetes cluster, and network levels. Future articles will go deeper into SaaS security topics.&lt;/p&gt; &lt;p&gt;&lt;a href="https://connect.redhat.com/en/partner-with-us/red-hat-saas-foundations"&gt;Red Hat SaaS Foundations&lt;/a&gt; is a partner program designed for building enterprise-grade SaaS platforms on Red Hat OpenShift or Red Hat Enterprise Linux, and deploying them across multiple cloud and non-cloud footprints. &lt;a href="http://https//mail.google.com/mail/?view=cm&amp;fs=1&amp;tf=1&amp;to=saas@redhat.com"&gt;Email&lt;/a&gt; us to learn more.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/07/27/saas-security-kubernetes-environments-layered-approach" title="SaaS security in Kubernetes environments: A layered approach"&gt;SaaS security in Kubernetes environments: A layered approach&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Alex Kubacki</dc:creator><dc:date>2022-07-27T07:00:00Z</dc:date></entry><entry><title>Quarkus 2.11.1.Final and 2.10.4.Final released - Fixing CVE-2022-2466, new Redis Client API, more customization for some core extensions and more</title><link rel="alternate" href="&#xA;                https://quarkus.io/blog/quarkus-2-11-1-final-released/&#xA;            " /><author><name>Guillaume Smet (https://twitter.com/gsmet_)</name></author><id>https://quarkus.io/blog/quarkus-2-11-1-final-released/</id><updated>2022-07-27T00:00:00Z</updated><published>2022-07-27T00:00:00Z</published><summary type="html">Today, we released both Quarkus 2.11.1.Final and Quarkus 2.10.4.Final. Quarkus 2.11.1.Final is, despite its name, the first 2.11 release. Both versions are fixing CVE-2022-2466 in the SmallRye GraphQL server extension (for real this time). Unfortunately, the previous fix introduced in 2.10.3.Final and the non-released 2.11.0.Final was incomplete and the issue...</summary><dc:creator>Guillaume Smet (https://twitter.com/gsmet_)</dc:creator><dc:date>2022-07-27T00:00:00Z</dc:date></entry><entry><title type="html">How to use Java Mission Control to monitor Java apps</title><link rel="alternate" href="http://www.mastertheboss.com/java/how-to-use-java-mission-control-to-monitor-java-apps/" /><author><name>F.Marchioni</name></author><id>http://www.mastertheboss.com/java/how-to-use-java-mission-control-to-monitor-java-apps/</id><updated>2022-07-25T07:37:43Z</updated><content type="html">This article is whirlwind tour across the Java Flight Recorder (JFR) and the Java Mission Control (JMC) suite. At the end of it, you will be able to monitor, collect diagnostic data and profile any running Java application. What is Java Flight Recorder? Firstly, why do we need another tool to monitor Java ? As ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry></feed>
